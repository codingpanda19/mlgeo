{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f933ae",
   "metadata": {},
   "source": [
    "# ___\n",
    "\n",
    "# [ Machine Learning in Geosciences ]\n",
    "\n",
    "**Department of Applied Geoinformatics and Carthography, Charles University** \n",
    "\n",
    "*Lukas Brodsky lukas.brodsky@natur.cuni.cz*\n",
    "\n",
    "    \n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c425873f",
   "metadata": {},
   "source": [
    "# Machine Learning Project!\n",
    "\n",
    "Step 5 and 6\n",
    "\n",
    "Goal: This notebook demonstrates the **selected model fitting and fine-tuning** steps for machine learning algorithms.  \n",
    "\n",
    "Content: **Select model and fine tune** the model\n",
    "\n",
    "    5.1/ Select model, train it and evaluate\n",
    "    5.2/ Cros-validate\n",
    "    \n",
    "    6.1/ Fine-tune the model with grid search\n",
    "    6.2/ and randomized search\n",
    "    \n",
    "    6.3/ Analyze the best model\n",
    "    6.4/ and evaluate it on the test data set. \n",
    "___    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde77e9d",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# add more based on the topic of the lab\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# plotting \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# path to the current lab directory - set individually!!!\n",
    "# TODO HERE! \n",
    "PROJECT_DIR = \"./\"\n",
    "if os.path.isdir(PROJECT_DIR): \n",
    "    print('Ok continue.')\n",
    "else: \n",
    "    print('Nok, set correct path to your project directory!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967cb99",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58975fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# check the data set dir \n",
    "forest_path = os.path.join(PROJECT_DIR, \"forest_fires\")\n",
    "\n",
    "# function to read the csv file \n",
    "def load_local_data(data_path, csv_file):\n",
    "    csv_path = os.path.join(data_path, csv_file)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "# load data \n",
    "fires = load_local_data(forest_path, \"forestfires.csv\")\n",
    "\n",
    "# check header and some values \n",
    "fires.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f39365b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49c5baeb",
   "metadata": {},
   "source": [
    "### Splitting data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e401f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(fires\n",
    "                                       , test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a1b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad527617",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26122b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the selected attributes to Numpy ndarray \n",
    "X_train = np.array(train_set[['X', 'Y', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']], \n",
    "                   dtype=np.float64)\n",
    "y_train = np.array(train_set[['area']].values.ravel(), dtype=np.float64) \n",
    "\n",
    "# .values will give the values in a numpy array (shape: (n,1))\n",
    "# .ravel will convert that array shape to (n, ) (i.e. flatten it)\n",
    "#.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9cc174",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(test_set[['X', 'Y', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']], \n",
    "                   dtype=np.float64)\n",
    "y_test = np.array(test_set[['area']].values.ravel(), dtype=np.float64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74892a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34be4146",
   "metadata": {},
   "source": [
    "## Select and train a model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae519a6",
   "metadata": {},
   "source": [
    "### Decision tree (default param) \n",
    "Use a non-linear model - (assumption: the data relation is non-linear) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b289a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first fitting to evaluate everything works\n",
    "tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a241c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "fires_predictions = tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select our metrics\n",
    "\n",
    "# from sklearn import metrics\n",
    "# sorted(metrics.SCORERS.keys())\n",
    "# or https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a53cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the firs model evaluation (RMSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "tree_mse = mean_squared_error(y_test, fires_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(round(tree_rmse, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddec34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "tree_mae = mean_absolute_error(y_test, fires_predictions)\n",
    "print(round(tree_mae, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf511344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc559a6d",
   "metadata": {},
   "source": [
    "### Fine-tune the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee9c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Decision Tree regressor \n",
    "scores = cross_val_score(tree_reg, X_train, y_train,\n",
    "                         scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "tree_mae_scores = (-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddcd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    # print(\"Scores:\", scores)\n",
    "    print(\"Mean MAE:\", round(scores.mean(), 2))\n",
    "    print(\"Standard deviation:\", round(scores.std(), 2))\n",
    "\n",
    "display_scores(tree_mae_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4bfcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0721904",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b6841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Cross-validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# the model hyper-parameters \n",
    "# help: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html \n",
    "# DecisionTreeRegressor(splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, ...)\n",
    "\n",
    "param_grid = [\n",
    "    # try more combinations of hyperparameters\n",
    "    # 5 * 5 * 2 = 50\n",
    "     {'max_depth': [3, 4, 5, 10], 'min_samples_split': [3, 4, 5, 10], \n",
    "     'splitter': ['random', 'best']}\n",
    "  ]\n",
    "\n",
    "# grid seach application\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# train across 5 folds, that's a total of 50 * 5 = 250 rounds of training \n",
    "grid_search = GridSearchCV(tree_reg, param_grid, cv=5, scoring=\"neg_mean_absolute_error\",\n",
    "                            return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca55fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAWARE this step may take long time! \n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c70f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c05c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the score of each hyperparameter combination tested during the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d947560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a00ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(-mean_score, params)\n",
    "    \n",
    "# TODO: store the model with min. MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400ef2e4",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0af535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAWARE it can run long time! \n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'max_depth': randint(low=3, high=10),\n",
    "        'min_samples_split': randint(low=3, high=10),\n",
    "    }\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(tree_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=10, scoring=\"neg_mean_absolute_error\", random_state=42) \n",
    "\n",
    "rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5d7bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69163a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(-mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and evaluate it with test set!\n",
    "sel_model = grid_search.best_estimator_\n",
    "sel_predictions = sel_model.predict(X_test)\n",
    "print('MAE: {}'.format(round(mean_absolute_error(y_test,  sel_predictions), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select final model and evaluate it with test set!\n",
    "sel_model = rnd_search.best_estimator_\n",
    "sel_predictions = sel_model.predict(X_test)\n",
    "print('MAE: {}'.format(round(mean_absolute_error(y_test,  sel_predictions), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa177f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
