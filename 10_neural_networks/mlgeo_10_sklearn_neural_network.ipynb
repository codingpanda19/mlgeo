{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___\n",
    "\n",
    "# [ Machine Learning in Geosciences ]\n",
    "\n",
    "**Department of Applied Geoinformatics and Carthography, Charles University** \n",
    "\n",
    "*Lukas Brodsky lukas.brodsky@natur.cuni.cz*\n",
    "\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Neural Network \n",
    "\n",
    "Multi-Layer Perceptron architecture applied to Iris data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn API \n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data set splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# validation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# sample data\n",
    "from sklearn import datasets\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt \n",
    "# notebook solution\n",
    "%matplotlib inline \n",
    "# seaborn works on top of matplotlib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris data from sklearn\n",
    "# iris = datasets.load_iris()\n",
    "# or from seaborn\n",
    "df = sns.load_dataset('iris') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view sample of the data set \n",
    "import matplotlib.image as mpimg\n",
    "img = 'iris-dataset.png'\n",
    "img = mpimg.imread('iris-dataset.png')\n",
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the data set\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensionality\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualizace atributu - pruzkumova analyza \n",
    "sns.pairplot(data=df, hue = 'species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = df['species']\n",
    "df1 = df.copy()\n",
    "df1 = df1.drop('species', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the attributes \n",
    "X = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kodovani trid \n",
    "le = LabelEncoder()\n",
    "num_codes = le.fit_transform(reference) \n",
    "num_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes\n",
    "spec_code  = pd.concat([df['species'], pd.DataFrame(num_codes)], axis=1)\n",
    "\n",
    "for col in spec_code:\n",
    "    print(spec_code[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = num_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data (randomely) \n",
    "# nahodne rozdeleni \n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.7, random_state = 42)\n",
    "\n",
    "print(\"Trenovaci mnozina \", X_train.shape)\n",
    "print(\"Testovaci mnozina \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model instance and parameters\n",
    "\n",
    "# \"hidden_layer_sizes\": [(5), (10), (5,5), (10,10), (5,5,5), (10,10,10)]\n",
    "# \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "# \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "# \"max_iter\": [100, 200, 300, 500, 1000, 2000]\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(5, 5, 5), activation='identity', learning_rate='adaptive', max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fitting the model\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "# cv_strom = cross_validate(my_tree, X_train,y_train, cv=5, scoring='f1_macro', return_estimator=True)\n",
    "# print('Average F1-skore: {:.3f} '.format(cv_strom['test_score'].mean()))\n",
    "\n",
    "cv_nn = cross_validate(nn, X_train, y_train, cv=5, scoring='f1_macro', return_estimator=True)\n",
    "print('Average F1-skore: {:.3f} '.format(cv_nn['test_score'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on the test data set \n",
    "print('Accuray F1-score on test set: {:.3f}'.format(\n",
    "    round(f1_score(y_test, nn.predict(X_test), average='macro'), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(data=cm,linewidths=.5, annot=True, square=True, cmap='Blues')\n",
    "plt.ylabel('Reference')\n",
    "plt.xlabel('Predicted class')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
