{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Machine Learning in Geosciences ] \n",
    "Department of Applied Geoinformatics and Carthography, Charles University\n",
    "\n",
    "Lukas Brodsky lukas.brodsky@natur.cuni.cz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Algorithms: trees-based  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose**: plot the decision surfaces of forests of randomized trees trained on pairs of features of the iris dataset.\n",
    "\n",
    "The plot compares the decision surfaces learned by a decision tree classifier, by a random forest classifier and by an extra-trees classifier.\n",
    "\n",
    "The classifiers are built using the sepal width and the sepal length features only, on the second row using the petal length and sepal length only, and on the third row using the petal width and the petal length only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**: \n",
    "\n",
    "1/ vary the `max_depth` for the DecisionTreeClassifier, perhaps try max_depth=3 for the DecisionTreeClassifier\n",
    "\n",
    "2/ vary `n_estimators` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports for reading, visualizing\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# utilities\n",
    "from IPython.display import display\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.datasets import load_iris \n",
    "# import pylab as pl\n",
    "from sklearn import clone\n",
    "\n",
    "# models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# todo later update\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "\n",
    "colors = \"bry\"\n",
    "\n",
    "# Project dir\n",
    "PROJECT_DIR = \"./\"\n",
    "if os.path.isdir(PROJECT_DIR):\n",
    "    print('Ok continue.')\n",
    "else:\n",
    "    print('Nok, set correct path to your project directory!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tree models model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_classes = 3\n",
    "n_estimators = 30\n",
    "plot_colors = \"bry\"\n",
    "plot_step = 0.02\n",
    "pl.set_cmap(pl.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    DecisionTreeClassifier(max_depth=None),\n",
    "    RandomForestClassifier(n_estimators=n_estimators),\n",
    "    ExtraTreesClassifier(n_estimators=n_estimators)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (features[pair[0]], features[pair[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot decision boundary of Decision tree classifier, Random forest and Extra trees\n",
    "\n",
    "plot_idx = 1\n",
    "\n",
    "for pair in ([0, 1], [0, 2], [2, 3]):\n",
    "    for model in (DecisionTreeClassifier(),\n",
    "                  RandomForestClassifier(n_estimators=n_estimators),\n",
    "                  ExtraTreesClassifier(n_estimators=n_estimators)):\n",
    "        # We only take the two corresponding features\n",
    "        X = iris.data[:, pair]\n",
    "        y = iris.target\n",
    "\n",
    "        # Shuffle\n",
    "        idx = np.arange(X.shape[0])\n",
    "        np.random.seed(13)\n",
    "        np.random.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "\n",
    "        # Standardize\n",
    "        mean = X.mean(axis=0)\n",
    "        std = X.std(axis=0)\n",
    "        X = (X - mean) / std\n",
    "\n",
    "        # Train\n",
    "        clf = clone(model)\n",
    "        clf = model.fit(X, y)\n",
    "        \n",
    "        scores = model.score(X, y)\n",
    "        print('Model: {}, pair: {}, score: {}'.format(model, (features[pair[0]], features[pair[1]]), \n",
    "                                                      round(scores, 2)))  \n",
    "\n",
    "        # Plot the decision boundary\n",
    "        # print(plot_idx)\n",
    "        plt.subplot(3, 3, plot_idx) \n",
    "\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                             np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "        if isinstance(model, DecisionTreeClassifier):\n",
    "            Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            cs = plt.contourf(xx, yy, Z)\n",
    "        else:\n",
    "            for tree in model.estimators_:\n",
    "                Z = tree.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "                Z = Z.reshape(xx.shape)\n",
    "                cs = plt.contourf(xx, yy, Z, alpha=0.1)\n",
    "\n",
    "        # plt.axis(\"tight\")\n",
    "\n",
    "        # Plot the training points\n",
    "        for i, c in zip(range(n_classes), plot_colors):\n",
    "            idx = np.where(y == i)\n",
    "            plt.scatter(X[idx, 0], X[idx, 1], c=c, label=iris.target_names[i])\n",
    "\n",
    "        plt.axis(\"tight\")\n",
    "\n",
    "        plot_idx += 1\n",
    "\n",
    "plt.suptitle(\"Decision surfaces of a decision tree, of a random forest, and of \"\n",
    "             \"an extra-trees classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "nav_menu": {
   "height": "252px",
   "width": "333px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
